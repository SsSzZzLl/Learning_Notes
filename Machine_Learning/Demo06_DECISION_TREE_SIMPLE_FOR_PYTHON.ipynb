{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell # 这个对象设置所有行全部输出\n",
    "  \n",
    "# 设置该对象ast_node_interactivity的属性值为all，表示notebook下每一行有输出的代码全部输出运算结果\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# 解决坐标轴刻度负号乱码\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 解决中文乱码问题\n",
    "plt.rcParams['font.sans-serif'] = ['Simhei']\n",
    "plt.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>是否陪伴</th>\n",
       "      <th>是否玩游戏</th>\n",
       "      <th>渣男</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>不是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>不是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>不是</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   是否陪伴  是否玩游戏  渣男\n",
       "0     0      1   是\n",
       "1     0      1   是\n",
       "2     0      0  不是\n",
       "3     1      1  不是\n",
       "4     1      1  不是"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据准备\n",
    "row_data = {\n",
    "  '是否陪伴' : [0, 0, 0, 1, 1],\n",
    "   '是否玩游戏' : [1, 1, 0, 1, 1],\n",
    "   '渣男' : ['是', '是', '不是', '不是', '不是']\n",
    "}\n",
    "\n",
    "# 构建为dataframe\n",
    "dataset = pd.DataFrame(row_data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前输入数据的信息熵为0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "# 1.实现信息熵计算函数\n",
    "def calEntropy(dataset):\n",
    "  '''\n",
    "  cal Entropy values\n",
    "  '''\n",
    "  \n",
    "  # 先获取样本的总数\n",
    "  n_samples = dataset.shape[0]\n",
    "  \n",
    "  #获取标签的所有类别\n",
    "  classes = dataset.iloc[:, -1].value_counts()\n",
    "  \n",
    "  # 计算每一类标签占据样本总数的百分比\n",
    "  px_i = classes / n_samples\n",
    "  \n",
    "  return (-px_i * np.log2(px_i)).sum() # 计算所得的信息熵\n",
    "\n",
    "def text():\n",
    "  print('当前输入数据的信息熵为{}'.format(calEntropy(dataset)))\n",
    "  \n",
    "text()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "依据当前第1个特征对数据集dataset进行划分，此时得到了2个划分后的子节点，当前特征划分后所有子节点的总信息熵为:0.5509775004326937\n",
      "第1个特征列划分后所得的信息增益为:0.4199730940219749\n",
      "依据当前第2个特征对数据集dataset进行划分，此时得到了2个划分后的子节点，当前特征划分后所有子节点的总信息熵为:0.8\n",
      "第2个特征列划分后所得的信息增益为:0.17095059445466854\n",
      "经过最优划分特征的选取和计算，当前数据集中，本次划分可以采用的最优划分特征为:是否陪伴\n"
     ]
    }
   ],
   "source": [
    "# 2.定义最优列选择函数，输入经过信息增益计算后的最优列的索引值（第几个特征是本次的最优划分特征）\n",
    "def selectBestSplit(dataset):\n",
    "  '''\n",
    "  最优划分特征的选择\n",
    "  '''\n",
    "  # 先计算原始的信息熵（父节点信息熵）\n",
    "  base_entropy = calEntropy(dataset)\n",
    "  \n",
    "  # 初始化一个变量，用于保存计算后所得的信息增益值\n",
    "  baseGain = 0\n",
    "  \n",
    "  # 初始化一个变量，用于保存挑选出的最优划分特征的列索引的值，因为列索引的值都是从0开始的，所以改变了的初值置为-1\n",
    "  axis = -1\n",
    "  \n",
    "  #遍历所有特征\n",
    "  for i in range(dataset.shape[1] - 1):\n",
    "    \n",
    "    #提取出当前特征的所有取值\n",
    "    levels = dataset.iloc[:, i].value_counts().index\n",
    "    \n",
    "    # 初始化一个变量，用于保存子节点的信息熵计算结果\n",
    "    ents = 0\n",
    "    \n",
    "    # 加一个计数，只是为了最终的结果输出\n",
    "    m = 0\n",
    "    \n",
    "    # 对当前特征列的每一个所取到的值遍历 —— 表示可以依据当前特征将数据集划分为多少个子集\n",
    "    for j in levels:\n",
    "      m += 1\n",
    "      \n",
    "      # 获取划分到当前子节点的所有样本所构成的dataframe\n",
    "      chile_dataset = dataset[dataset.iloc[:, i] == j] # boolean索引 —— 在dataset中，找出这样的样本，样本中第i特征列取到j这个值的索引样本\n",
    "      \n",
    "      # 计算当前子节点的信息熵\n",
    "      ent = calEntropy(chile_dataset)\n",
    "      \n",
    "      # 计算权重\n",
    "      ents += (chile_dataset.shape[0] / dataset.shape[0]) * ent\n",
    "      \n",
    "    print('依据当前第{}个特征对数据集dataset进行划分，此时得到了{}个划分后的子节点，当前特征划分后所有子节点的总信息熵为:{}'.format(i + 1, m, ents))\n",
    "    \n",
    "    # 计算采用当前第i个特征划分后所得的当前特征列划分下的信息增益\n",
    "    infoGain = base_entropy - ents\n",
    "    \n",
    "    print('第{}个特征列划分后所得的信息增益为:{}'.format(i + 1, infoGain))\n",
    "    \n",
    "    # 判断如果当前特征列划分后所得的信息增益大于前一个特征列划分后所记录下来信息增益，就说明采用当前特征列做划分是更好的\n",
    "    if infoGain > baseGain:\n",
    "      \n",
    "      # 将当前特征列的信息增益值更新到全局（baseGain）\n",
    "      baseGain = infoGain\n",
    "      \n",
    "      axis = i\n",
    "\n",
    "  print('经过最优划分特征的选取和计算，当前数据集中，本次划分可以采用的最优划分特征为:{}'.format(dataset.columns[axis]))\n",
    "\n",
    "  return axis\n",
    "\n",
    "def test():\n",
    "  selectBestSplit(dataset)\n",
    "  \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "依据当前第1个特征对数据集dataset进行划分，此时得到了2个划分后的子节点，当前特征划分后所有子节点的总信息熵为:0.5509775004326937\n",
      "第1个特征列划分后所得的信息增益为:0.4199730940219749\n",
      "依据当前第2个特征对数据集dataset进行划分，此时得到了2个划分后的子节点，当前特征划分后所有子节点的总信息熵为:0.8\n",
      "第2个特征列划分后所得的信息增益为:0.17095059445466854\n",
      "经过最优划分特征的选取和计算，当前数据集中，本次划分可以采用的最优划分特征为:是否陪伴\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>是否玩游戏</th>\n",
       "      <th>渣男</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>不是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>不是</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   是否玩游戏  渣男\n",
       "3      1  不是\n",
       "4      1  不是"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.按照选出的最优划分特征对当前数据集开始进行划分\n",
    "def getSplitData(dataset, axis, value):\n",
    "  '''\n",
    "  按照给定选出的最优划分特征切分当前数据集\n",
    "  :params dataset:指定需要切分的数据集\n",
    "  :params axis:选出的最优划分特征列索引的值\n",
    "  :params value:指定最优划分特征列中的哪一个属性值进行划分\n",
    "  '''\n",
    "  \n",
    "  # 按照已获得的最优划分特征列索引值获取该列的所有取值\n",
    "  best_col_name = dataset.columns[axis]\n",
    "  \n",
    "  # 对应best_col中指定的value这个值，将该值的所有行全部过滤出来，并删除最优化发特征列，即得切分后的数据集\n",
    "  return dataset.loc[dataset[best_col_name] == value, :].drop(best_col_name, axis = 1) # boolean索引\n",
    "\n",
    "getSplitData(dataset, selectBestSplit(dataset), 1)\n",
    "# getSplitData(dataset, selectBestSplit(dataset), 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "渣男\n",
       "不是    3\n",
       "是     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:, -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "依据当前第1个特征对数据集dataset进行划分，此时得到了2个划分后的子节点，当前特征划分后所有子节点的总信息熵为:0.5509775004326937\n",
      "第1个特征列划分后所得的信息增益为:0.4199730940219749\n",
      "依据当前第2个特征对数据集dataset进行划分，此时得到了2个划分后的子节点，当前特征划分后所有子节点的总信息熵为:0.8\n",
      "第2个特征列划分后所得的信息增益为:0.17095059445466854\n",
      "经过最优划分特征的选取和计算，当前数据集中，本次划分可以采用的最优划分特征为:是否陪伴\n",
      "依据当前第1个特征对数据集dataset进行划分，此时得到了2个划分后的子节点，当前特征划分后所有子节点的总信息熵为:0.0\n",
      "第1个特征列划分后所得的信息增益为:0.9182958340544896\n",
      "经过最优划分特征的选取和计算，当前数据集中，本次划分可以采用的最优划分特征为:是否玩游戏\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'是否陪伴': {0: {'是否玩游戏': {0: '不是', 1: '是'}}, 1: '不是'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.原生python代码实现基于最大信息增益划分数据集并递归建造决策树模型的ID3算法模型复现\n",
    "def createID3Tree(dataset):  \n",
    "  '''\n",
    "    :params dataset:指定的数据集\n",
    "    :return:以字典结构构建的最终ID3算法决策树模型\n",
    "  '''\n",
    "  \n",
    "  # 先取出数据集中所有特征列 —— 取出的是所有特征的列索引名称\n",
    "  feature_list = list(dataset.columns)\n",
    "  \n",
    "  # 获取数据集中最后一列的列索引名称 —— 即标签 —— 然后再获取标签的所有类别及各类别的样本数量\n",
    "  classes = dataset.iloc[:, -1].value_counts()\n",
    "  \n",
    "  # 判断：当前数据集中标签的各个类别中的各个类别及各类别的样本数量中，样本数量最大的类别的样本数量是否直接等于样本容量的大小 ——   即：表示当前样本中是否所有样本同属同一类别\n",
    "  # 或者：当前数据集是否只有一个特征列\n",
    "  if classes[0] == dataset.shape[0] or dataset.shape[1] == 1:\n",
    "    return classes.index[0]\n",
    "  \n",
    "  # 开始真正的ID3算法递归构建决策树的过程\n",
    "  \n",
    "  # 先选出最优划分特征列\n",
    "  axis = selectBestSplit(dataset)\n",
    "  \n",
    "  # 根据选出的最优划分特征的列索引，获取该列索引对应的该列特征\n",
    "  best_features = feature_list[axis]\n",
    "\n",
    "  # 准备一个字典，用字典结构存储决策树的信息\n",
    "  ID3_Tree = {\n",
    "    best_features : {}\n",
    "  }\n",
    "  \n",
    "  # 将当前选出的最优划分特征列从数据集中删除\n",
    "  del feature_list[axis]\n",
    "  \n",
    "  # 获取最优划分特征列的所有取值\n",
    "  value_list = list(set(dataset.iloc[:, axis])) # set是python中的集合类型，自带去重特性 \n",
    "  \n",
    "  # for循环遍历当前选定的最优划分特征列的每一个取值\n",
    "  for value in value_list:\n",
    "    \n",
    "    # 开始递归建造ID3决策树\n",
    "    ID3_Tree[best_features][value] = createID3Tree(getSplitData(dataset, axis, value))\n",
    "    \n",
    "  return ID3_Tree\n",
    "\n",
    "final_ID3Tree = createID3Tree(dataset)\n",
    "\n",
    "final_ID3Tree\n",
    "  \n",
    "'''\n",
    "{\n",
    "  '是否陪伴':{\n",
    "    0:{\n",
    "      '是否玩游戏':{\n",
    "        0: '不是',\n",
    "        1: '是'\n",
    "      }\n",
    "    }, \n",
    "    1: '不是'\n",
    "  }\n",
    "}\n",
    "'''    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataMiningVenvsForPython38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
